{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import wandb\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "# Style for making nice-looking paper plots with page-scale figure size units\n",
    "sns.set_theme(\n",
    "    style=\"ticks\",\n",
    "    context=\"paper\",\n",
    "    palette=\"deep\",\n",
    "    rc={\n",
    "        \"font.size\": 5,\n",
    "        \"axes.titlesize\": 6,\n",
    "        \"axes.labelsize\": 6,\n",
    "        \"axes.labelpad\": 2,\n",
    "        \"xtick.labelsize\": 4.5,\n",
    "        \"ytick.labelsize\": 4.5,\n",
    "        \"legend.title_fontsize\": 4.5,\n",
    "        \"legend.fontsize\": 4.5,\n",
    "        \"legend.markerscale\": 0.5,\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.linewidth\": 0.4,\n",
    "        \"xtick.major.width\": 0.4,\n",
    "        \"ytick.major.width\": 0.4,\n",
    "        \"xtick.major.size\": 2.5,\n",
    "        \"ytick.major.size\": 2.5,\n",
    "        \"xtick.minor.size\": 1.5,\n",
    "        \"ytick.minor.size\": 1.5,\n",
    "        \"xtick.minor.width\": 0.2,\n",
    "        \"ytick.minor.width\": 0.2,\n",
    "        \"figure.constrained_layout.use\": True,\n",
    "        \"figure.dpi\": 200,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "# Weights & Biases\n",
    "api = wandb.Api()\n",
    "\n",
    "\n",
    "def get_run_results(\n",
    "    entity: str,\n",
    "    project: str,\n",
    "    metrics: list[str],\n",
    "    filters: dict[str, Any],\n",
    "    posthoc_nested_config_filters: dict[str, Any] = {},\n",
    "    x_axis: str = \"epoch\",\n",
    "    user: str | None = None,\n",
    "    save_path: str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Pulls data from the W&B API and returns a dataframe with either the best epoch performance for each run\n",
    "    (when `best_epoch=True`) or the entire training trajectory across runs (when `best_epoch=False`).\n",
    "\n",
    "    Args:\n",
    "        entity (str): W&B entity.\n",
    "        dataset (str): The W&B project.\n",
    "        metrics (list[str]): Logged metrics we want to keep.\n",
    "        filters (dict[str, Any]): W&B API filters used to select only a subset of runs. See code below for examples.\n",
    "        x_axis (str): The x-axis to plot the metrics against.\n",
    "        save_path (str, optional): Optionally save the resulting dataframe. Note that if the file already exists, we retrieve its data and return that rather than querying the API. Defaults to `None`.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe of results. It contains the run id, epoch, config arguments, and `metrics`.\n",
    "    \"\"\"\n",
    "    # If data has already been downloaded, don't make another API call\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Loading from cached file {save_path}...\")\n",
    "        data = pd.read_csv(save_path)\n",
    "        return data\n",
    "\n",
    "    # Fetch all run data from the API\n",
    "    runs = api.runs(f\"{entity}/{project}\", filters=filters)\n",
    "    if user is not None:\n",
    "        runs = [run for run in runs if run.user.username == user]\n",
    "    filtered_runs = []\n",
    "    for run in runs:\n",
    "        config = run.config\n",
    "        is_valid = True\n",
    "        for key, value in posthoc_nested_config_filters.items():\n",
    "            nested_attribute = key.split(\".\")\n",
    "            attribute_config = deepcopy(config)\n",
    "            for attribute in nested_attribute:\n",
    "                if attribute not in attribute_config:\n",
    "                    is_valid = False\n",
    "                    break\n",
    "                attribute_config = attribute_config[attribute]\n",
    "            if isinstance(attribute_config, list):\n",
    "                attribute_config = \",\".join(attribute_config)\n",
    "            if attribute_config != value:\n",
    "                is_valid = False\n",
    "                break\n",
    "        if is_valid:\n",
    "            filtered_runs.append(run)\n",
    "    runs = filtered_runs\n",
    "\n",
    "    # Collect all of the run histories into a dataframe\n",
    "    data = []\n",
    "    for run in runs:\n",
    "        if \"self\" in run.config:\n",
    "            del run.config[\"self\"]  # Present in SGD runs, but causes python errors\n",
    "        # List values cause problems when assigning to a dataframe\n",
    "        for key, value in run.config.items():\n",
    "            if isinstance(value, list):\n",
    "                run.config[key] = \", \".join(value)\n",
    "        run_data = run.history(samples=1000000, x_axis=x_axis, keys=metrics)\n",
    "        run_data = run_data.assign(run_id=run.id, **run.config)\n",
    "        data.append(run_data)\n",
    "    data = pd.concat(data)\n",
    "\n",
    "    # Re-order columns\n",
    "    data = data[[\"run_id\", x_axis] + metrics + list(run.config.keys())]\n",
    "\n",
    "    # Cache data\n",
    "    if save_path is not None:\n",
    "        data.to_csv(save_path, index=False)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Plotting\n",
    "\"\"\"default method order in plots\n",
    "\n",
    "    Example:\n",
    "    [\"prequential\", \"train\", ...]\n",
    "\"\"\"\n",
    "default_method_order = [\n",
    "]\n",
    "\n",
    "\"\"\"default method color in plots\n",
    "\n",
    "    Example:\n",
    "    \"prequential\": sns.color_palette()[0],\n",
    "    \"train\": sns.color_palette()[1],\n",
    "    ...\n",
    "\"\"\"\n",
    "default_method_hue = {\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\"rename metrics\n",
    "\n",
    "    Example: \n",
    "    \"val_tasks/n_sample_loss_train\": \"Training error\",\n",
    "    \"b_kl\": \"Generalization error\",\n",
    "\"\"\"\n",
    "metric_name_map = {\n",
    "}\n",
    "\n",
    "def custom_plot(\n",
    "    ax,\n",
    "    data,\n",
    "    x,\n",
    "    y,\n",
    "    xlabel,\n",
    "    ylabel,\n",
    "    hue=None,\n",
    "    hide_legend: bool = True,\n",
    "    errorbar: str = \"se\",\n",
    "    **kwargs,\n",
    "):\n",
    "                        # methods = data[\"method\"].unique()\n",
    "    hue_order = None    # [m for m in default_method_order if m in methods]\n",
    "    palette = None      # {m: default_method_hue[m] for m in methods}\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=data,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        hue=hue,\n",
    "        hue_order=hue_order,\n",
    "        palette=palette,\n",
    "        errorbar=errorbar,\n",
    "        ax=ax,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    ax.set(\n",
    "        xscale=\"log\",\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel, #metric_name_map[y],\n",
    "    )\n",
    "    if hide_legend:\n",
    "        ax.legend().remove()\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def smooth_data(\n",
    "    data,\n",
    "    metrics,\n",
    "    sigma=20.0,\n",
    "):\n",
    "    metrics = [m for m in metrics if m in data.columns]\n",
    "\n",
    "    def smooth(x, smoothing_columns, sigma):\n",
    "        x.loc[:, smoothing_columns] = gaussian_filter1d(\n",
    "            x[smoothing_columns], sigma, axis=0\n",
    "        )\n",
    "        return x\n",
    "\n",
    "    data = data.sort_values([\"run_id\",\"epoch\"])\n",
    "    data = (\n",
    "        data.groupby(\"run_id\")\n",
    "        .apply(\n",
    "            lambda x: smooth(x, metrics, sigma=sigma),\n",
    "            include_groups=False,\n",
    "        )\n",
    "        .reset_index(level=\"run_id\")\n",
    "    )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of how to use the API to get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example from the project \"Prequential-ICL\"\n",
    "data_icl_linreg = get_run_results(\n",
    "    entity=\"dhanya-shridar\",\n",
    "    project=\"Prequential-ICL\",\n",
    "    metrics=[\"val_tasks/n_sample_loss_nexttoken\"],\n",
    "    x_axis=\"n_samples\",\n",
    "    filters={\n",
    "        \"config.dataset.name\": \"linear_regression\",\n",
    "        \"config.task_name\": \"meta_optimizer\",\n",
    "        \"tags\": {\n",
    "            \"$in\": [\n",
    "                \"experiments/prequential_vs_train/regression\",\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    user=\"ericelmoznino\",\n",
    "    save_path=\"data/icl_linreg.csv\",\n",
    ")\n",
    "data_icl_linreg = smooth_data(data_icl_linreg, [\"val_tasks/n_sample_loss_nexttoken\"])\n",
    "data_icl_linreg[\"method\"] = data_icl_linreg[\"meta_objective\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(5.5, 1.3))\n",
    "\n",
    "custom_plot(axs[0], data_icl_linreg, x=\"n_samples\", y=\"val_tasks/n_sample_loss_nexttoken\")\n",
    "custom_plot(axs[1], data_icl_linreg, x=\"n_samples\", y=\"val_tasks/n_sample_loss_nexttoken\")\n",
    "custom_plot(axs[2], data_icl_linreg, x=\"n_samples\", y=\"val_tasks/n_sample_loss_nexttoken\")\n",
    "\n",
    "axs[0].set(title=\"First plot\")\n",
    "axs[1].set(title=\"Second plot\", ylabel=None)\n",
    "axs[2].set(title=\"Third plot\", ylabel=None)\n",
    "\n",
    "fig.savefig(\"saved/example.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "This section contains all the plots that will go in Appendix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvPreq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
